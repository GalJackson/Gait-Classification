{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pose estimation evaluation metrics\n",
    "\n",
    "This will be used to get an idea of how accurate YOLOv8/Detectron2 is at extracting the pose of the patient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import re\n",
    "import tkinter\n",
    "from tkinter import filedialog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select random frames from a given patient and convert to individual images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory where input videos are stored\n",
    "video_dir = \"../Videos/Cropped/OAW06/\"\n",
    "\n",
    "# loop through all files in the video directory\n",
    "for video_name in os.listdir(video_dir):\n",
    "    if video_name.endswith(\".mp4\"):\n",
    "        # construct the full video path\n",
    "        video_path = os.path.join(video_dir, video_name)\n",
    "        print(f\"Video {video_name}:\")\n",
    "        \n",
    "        # converting random frames from the video to images\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "        # randomly select three frames\n",
    "        frame_i = random.sample(range(0, int(frame_count)), 3)\n",
    "\n",
    "        for i in frame_i:\n",
    "            # set the current frame position\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "            success, image = cap.read()\n",
    "            if success: \n",
    "                # save frame as a jpg image\n",
    "                cv2.imwrite(\"temp_images/\" + video_name[:-4] + f\"-frame{i}.jpg\", image)  \n",
    "                print(f\"Frame {i} converted to image.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Or instead, select N random frames from a single video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkinter.Tk().withdraw() # prevents an empty tkinter window from appearing\n",
    "video_path = filedialog.askopenfilename(title=\"input\")\n",
    "video_name = os.path.basename(video_path)\n",
    "\n",
    "n = 10 # number of frames to select per video\n",
    "\n",
    "# converting random frames from the video to images\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "# randomly select three frames\n",
    "frame_i = random.sample(range(0, int(frame_count)), n)\n",
    "\n",
    "for i in frame_i:\n",
    "    # set the current frame position\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "    success, image = cap.read()\n",
    "    if success: \n",
    "        # save frame as a jpg image\n",
    "        cv2.imwrite(\"temp_images/\" + video_name[:-4] + f\"-frame{i}.jpg\", image)  \n",
    "        print(f\"Frame {i} converted to image.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keypoint Annotation Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sections of this code have been created with the help of https://www.geeksforgeeks.org/displaying-the-coordinates-of-the-points-clicked-on-the-image-using-python-opencv/\n",
    "\n",
    "# list of body keypoints I will be collecting\t\n",
    "keypoints = [\n",
    "    \"RAnkle\",\n",
    "\t\"LAnkle\",\n",
    "\t\"RKnee\",\n",
    "\t\"LKnee\",\n",
    "\t\"RHip\",\n",
    "\t\"LHip\",\n",
    "\t\"RShoulder\"\n",
    "]\n",
    "\n",
    "kp_coco_idxs = {\n",
    "    \"RAnkle\": 16,\n",
    "\t\"LAnkle\": 15,\n",
    "\t\"RKnee\": 14,\n",
    "\t\"LKnee\": 13,\n",
    "\t\"RHip\": 12,\n",
    "\t\"LHip\": 11,\n",
    "\t\"RShoulder\": 6\n",
    "}\n",
    "\n",
    "# function to display the coordinates of of the points clicked on the image \n",
    "def click_event(event, x, y, flags, params):\n",
    "\tglobal current_kp_index \n",
    "\n",
    "\t# checking for left mouse clicks \n",
    "\tif event == cv2.EVENT_LBUTTONDOWN: \n",
    "\n",
    "\t\tclicks[f\"{keypoints[current_kp_index]}_x\"] = x\n",
    "\t\tclicks[f\"{keypoints[current_kp_index]}_y\"] = y\n",
    "\n",
    "\t\t# displaying the coordinates on the Shell \n",
    "\t\tprint(x, ' ', y) \n",
    "\n",
    "\t\t# displaying the coordinates on the image window \n",
    "\t\tfont = cv2.FONT_HERSHEY_SIMPLEX \n",
    "\t\t# cv2.putText(img, str(x) + ',' + str(y), (x,y), font, 1, (255, 0, 0), 2) \n",
    "\n",
    "\t\t# displaying the keypoint number on the image window\n",
    "\t\tkp_coco_idx = kp_coco_idxs[keypoints[current_kp_index]]\n",
    "\t\tcv2.putText(img, str(kp_coco_idx), (x,y), font, 1, (255, 0, 0), 2) \n",
    "\t\t\n",
    "\t\t# draw a circle at the click location\n",
    "\t\tcv2.circle(img, (x, y), 5, (0, 255, 0), -1)\n",
    "\n",
    "\t\t# check if there are more prompts\n",
    "\t\tif current_kp_index < len(keypoints) - 1:\n",
    "\t\t\tcurrent_kp_index += 1\n",
    "\t\t\tdisplay_prompt(img)\n",
    "\t\telse:\n",
    "\t\t\tcv2.putText(img, \"All points collected.\", (10, 30), font, 0.7, (0, 255, 0), 2)\n",
    "\t\t\tcv2.imshow('image', img)\n",
    "\n",
    "\n",
    "def display_prompt(image):\n",
    "    prompt = keypoints[current_kp_index]\n",
    "    img_with_prompt = image.copy()\n",
    "    cv2.putText(img_with_prompt, prompt, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "    cv2.imshow('image', img_with_prompt)\n",
    "\n",
    "\n",
    "def extract_frame_num(im_name):\n",
    "\t# regular expression to extract the number before '.jpg'\n",
    "\tp = r'frame(\\d+)\\.jpg$'\n",
    "\n",
    "\treturn re.search(p, im_name).group(1)\n",
    "\n",
    "\n",
    "def extract_file_name(im_name):\n",
    "\t# regular expression to extract the string before '-frame' and '.jpg'\n",
    "\tp = r'^(.*)-frame\\d+\\.jpg$'\n",
    "\n",
    "\treturn re.search(p, im_name).group(1) + \".mp4\"\n",
    "\n",
    "\n",
    "if __name__==\"__main__\": \n",
    "\n",
    "\timg_directory = 'temp_images'\n",
    "\toutput = pd.DataFrame()\n",
    "\n",
    "\tfor img_name in os.listdir(img_directory):\n",
    "\t\tif img_name.endswith(('.png', '.jpg', '.jpeg')):\n",
    "\t\t\timg_path = os.path.join(img_directory, img_name)\n",
    "\n",
    "            # Reading the image\n",
    "\t\t\timg = cv2.imread(img_path, 1)\n",
    "\t\t\t# img = cv2.resize(img, (int(1080/2), int(1920/2))) # resizing as original size too big to view on monitor\n",
    "\n",
    "            # initialize the current keypoint index and clicks dictionary\n",
    "\t\t\tcurrent_kp_index = 0\n",
    "\n",
    "\t\t\tclicks = {f\"{name}_x\": 0 for name in keypoints}\n",
    "\t\t\tclicks.update({f\"{name}_y\": 0 for name in keypoints})\n",
    "\t\t\tclicks[\"file_name\"] = extract_file_name(img_name)\n",
    "\t\t\tclicks[\"frame\"] = extract_frame_num(img_name)\n",
    "\t\t\t\n",
    "\n",
    "            # display the initial prompt\n",
    "\t\t\tdisplay_prompt(img)\n",
    "\n",
    "            # setting mouse handler for the image and calling the click_event() function\n",
    "\t\t\tcv2.setMouseCallback(\"image\", click_event)\n",
    "\n",
    "            # wait for a key to be pressed to exit\n",
    "\t\t\tkey = cv2.waitKey(0)\n",
    "\t\t\tif key == ord(\"2\"):\n",
    "\t\t\t\t# resizing as original size too big to view on monitor\n",
    "\t\t\t\timg = cv2.resize(img, (int(1080/2), int(1920/2))) \n",
    "\t\t\t\tdisplay_prompt(img)\n",
    "\t\t\t\tcv2.waitKey(0)\n",
    "\t\t\t\t\n",
    "\t\t\t\t# multiplying all values in the df by 2 to account for the resizing prior to annotation\n",
    "\t\t\t\tclicks = {key: (value * 2 if isinstance(value, int) else value) for (key, value) in clicks.items()}\n",
    "\n",
    "\t\t\tcv2.destroyAllWindows()\n",
    "\n",
    "\t\t\toutput = pd.concat([output,  pd.DataFrame([clicks])], ignore_index=True)\n",
    "\n",
    "\toutput.to_csv(f\"../Keypoint-Annotations/{img_name[:5]}.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDJ - Percentage of Detected Joints \n",
    "\n",
    "Calculated by finding the torso diameter (diagonal from shoulder to hip), then checking if the distance from the true keypoint to the predicted keypoint is < 0.2 * torso diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter\n",
    "from tkinter import filedialog\n",
    "from scipy.spatial import distance\n",
    "\n",
    "keypoints = [\n",
    "    \"RAnkle\",\n",
    "\t\"LAnkle\",\n",
    "\t\"RKnee\",\n",
    "\t\"LKnee\",\n",
    "\t\"RHip\",\n",
    "\t\"LHip\"\n",
    "]\n",
    "\n",
    "def calculate_pdj_thold(row):\n",
    "    # calculate the PDJ threshold = 0.2 * torso diameter (distance from left hip to right shoulder)\n",
    "    \n",
    "    torso_diameter = distance.euclidean(row[[\"RShoulder_x\", \"RShoulder_y\"]], row[[\"LHip_x\", \"LHip_y\"]]) # distance from left hip to right shoulder\n",
    "    return torso_diameter * 0.2\n",
    "\n",
    "def find_prediction(row, model_type):\n",
    "    if model_type == \"detectron\":\n",
    "        pred_path = f\"detectron_exports/{row['file_name'][:-4]}.csv\"\n",
    "        pred_df = pd.read_csv(pred_path)\n",
    "    elif model_type == \"yolo\":\n",
    "        pred_path = f\"yolo_exports/{row['file_name'][:-4]}.csv\"\n",
    "        pred_df = pd.read_csv(pred_path)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type.\")\n",
    "    \n",
    "\n",
    "    return pred_df.loc[int(row[\"frame\"])]\n",
    "\n",
    "\n",
    "def calculate_kp_distances(row, kp):\n",
    "    return distance.euclidean(row[[f\"{kp}_x\", f\"{kp}_y\"]], row[[f\"{kp}_x_p\", f\"{kp}_y_p\"]])\n",
    "\n",
    "\n",
    "def calculate_kp_detected(row, kp):\n",
    "    if row[f\"{kp}_distance\"] < row[\"PDJ_thold\"]:\n",
    "        return 1\n",
    "    else:  \n",
    "        return 0\n",
    "\n",
    "\n",
    "if __name__==\"__main__\": \n",
    "    # load annotation file\n",
    "    tkinter.Tk().withdraw() # prevents an empty tkinter window from appearing\n",
    "    pose_labels_path = filedialog.askopenfilename(title=\"Select label file\")\n",
    "    labels_df = pd.read_csv(pose_labels_path, index_col=0)\n",
    "\n",
    "    # create a df of the predictions that correspond to each row in the annotation df\n",
    "    # For YOLO\n",
    "    pred_df_yolo = pd.DataFrame()\n",
    "    pred_df_yolo = labels_df.apply(lambda row: find_prediction(row, model_type=\"yolo\"), axis=1)\n",
    "    pred_df_yolo = pred_df_yolo.rename(columns=lambda x: x + '_p') # distinguish between annotation and prediction columns\n",
    "\n",
    "    # For Detectron\n",
    "    pred_df_detectron = pd.DataFrame()\n",
    "    pred_df_detectron = labels_df.apply(lambda row: find_prediction(row, model_type=\"detectron\"), axis=1)\n",
    "    pred_df_detectron = pred_df_detectron.rename(columns=lambda x: x + '_p') # distinguish between annotation and prediction columns\n",
    "\n",
    "    # add the prediction and label dfs together\n",
    "    df_yolo = pd.concat([labels_df, pred_df_yolo], axis=1)\n",
    "    df_detectron = pd.concat([labels_df, pred_df_detectron], axis=1)\n",
    "\n",
    "    # calculate the PDJ threshold for each frame in the annotation file\n",
    "    df_yolo[\"PDJ_thold\"] = labels_df.apply(calculate_pdj_thold, axis=1)\n",
    "    df_detectron[\"PDJ_thold\"] = labels_df.apply(calculate_pdj_thold, axis=1)\n",
    "\n",
    "    # calculate the distance between the predicted and true kp location\n",
    "    print(\"YOLO:\")\n",
    "    for kp in keypoints:\n",
    "        df_yolo[f\"{kp}_distance\"] = df_yolo.apply(lambda x: calculate_kp_distances(x, kp), axis=1)\n",
    "        df_yolo[f\"{kp}_detected\"] = df_yolo.apply(lambda x: calculate_kp_detected(x, kp), axis=1)\n",
    "        print(f'The PDJ for the {kp} is {len(df_yolo[df_yolo[f\"{kp}_detected\"] == 1]) / len(df_yolo[f\"{kp}_detected\"]) * 100}')\n",
    "        df_yolo.to_csv(\"yolo_PDJ.csv\", index=False)\n",
    "    \n",
    "    print(\"Detectron:\")\n",
    "    for kp in keypoints:\n",
    "        df_detectron[f\"{kp}_distance\"] = df_detectron.apply(lambda x: calculate_kp_distances(x, kp), axis=1)\n",
    "        df_detectron[f\"{kp}_detected\"] = df_detectron.apply(lambda x: calculate_kp_detected(x, kp), axis=1)\n",
    "        print(f'The PDJ for the {kp} is {len(df_detectron[df_detectron[f\"{kp}_detected\"] == 1]) / len(df_detectron[f\"{kp}_detected\"]) * 100}')\n",
    "        df_detectron.to_csv(\"detectron_PDJ.csv\", index=False)\n",
    "    \n",
    "    print(\"complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the performance if you swap left and right keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_L_R_columns(df):\n",
    "    # swaps 'L' and 'R' in the first character of column names\n",
    "    def swap_first_letter(col_name):\n",
    "        if col_name.endswith('_p'):\n",
    "            if col_name.startswith('L'):\n",
    "                return 'R' + col_name[1:]\n",
    "            elif col_name.startswith('R'):\n",
    "                return 'L' + col_name[1:]\n",
    "        else:\n",
    "            return col_name\n",
    "\n",
    "    # apply function to all column names\n",
    "    df = df.rename(columns=swap_first_letter)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_yolo = pd.read_csv(\"detectron_PDJ.csv\")\n",
    "df_yolo_inverse = pd.read_csv(\"detectron_PDJ.csv\")\n",
    "df_yolo_inverse = swap_L_R_columns(df_yolo_inverse)\n",
    "\n",
    "metrics_df = pd.DataFrame()\n",
    "\n",
    "for kp in keypoints:\n",
    "    # calculate distances and detection for inverse DataFrame\n",
    "    df_yolo_inverse[f\"{kp}_distance\"] = df_yolo_inverse.apply(lambda x: calculate_kp_distances(x, kp), axis=1)\n",
    "    df_yolo_inverse[f\"{kp}_detected\"] = df_yolo_inverse.apply(lambda x: calculate_kp_detected(x, kp), axis=1)\n",
    "\n",
    "    # calculate the percentage of rows where inverse detection is 1 and original detection is 0\n",
    "    condition = (df_yolo_inverse[f\"{kp}_detected\"] == 1) & (df_yolo[f\"{kp}_detected\"] == 0)\n",
    "    percentage = len(df_yolo_inverse[condition]) / len(df_yolo_inverse) * 100\n",
    "\n",
    "    print(f'The percentage of {kp} detected as 1 in df_yolo_inverse and 0 in df_yolo is {percentage:.2f}%')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the range of confidence values per group (detected/not detected based on PDJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'Keypoint': [],\n",
    "    'Min Conf (Failed PDJ)': [],\n",
    "    'Max Conf (Failed PDJ)': [],\n",
    "    'Min Conf (Passed PDJ)': [],\n",
    "    'Max Conf (Passed PDJ)': []\n",
    "}\n",
    "\n",
    "for keypoint_name in keypoints:\n",
    "    df_yolo[f'{keypoint_name}_normalized_distance'] = df_yolo[f'{keypoint_name}_distance'] / df_yolo['PDJ_thold']\n",
    "\n",
    "    # create a mask for blue points\n",
    "    blue_mask = (df_yolo[f'{keypoint_name}_detected'] == 1) | (df_yolo_inverse[f'{keypoint_name}_detected'] == 1)\n",
    "\n",
    "    # separate data based on the mask\n",
    "    blue_points = df_yolo[blue_mask]\n",
    "    red_points = df_yolo[~blue_mask]\n",
    "\n",
    "    # calculate min/max values\n",
    "    min_conf_failed = red_points[f'{keypoint_name}_conf_p'].min()\n",
    "    max_conf_failed = red_points[f'{keypoint_name}_conf_p'].max()\n",
    "    min_conf_passed = blue_points[f'{keypoint_name}_conf_p'].min()\n",
    "    max_conf_passed = blue_points[f'{keypoint_name}_conf_p'].max()\n",
    "    \n",
    "    # append the results to the dictionary\n",
    "    metrics['Keypoint'].append(keypoint_name)\n",
    "    metrics['Min Conf (Failed PDJ)'].append(min_conf_failed)\n",
    "    metrics['Max Conf (Failed PDJ)'].append(max_conf_failed)\n",
    "    metrics['Min Conf (Passed PDJ)'].append(min_conf_passed)\n",
    "    metrics['Max Conf (Passed PDJ)'].append(max_conf_passed)\n",
    "\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "metrics_df.to_csv(\"yolo_pdj_metrics.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate optimal confidence thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_thresholds = {}\n",
    "\n",
    "for keypoint_name in keypoints:\n",
    "    # extract the confidence scores for blue and red points\n",
    "    blue_conf = df_yolo.loc[(df_yolo[f'{keypoint_name}_detected'] == 1) | \n",
    "                            (df_yolo_inverse[f'{keypoint_name}_detected'] == 1), f'{keypoint_name}_conf_p']\n",
    "    red_conf = df_yolo.loc[~((df_yolo[f'{keypoint_name}_detected'] == 1) | \n",
    "                             (df_yolo_inverse[f'{keypoint_name}_detected'] == 1)), f'{keypoint_name}_conf_p']\n",
    "\n",
    "    # calculate the 90th percentile of blue points' confidence scores\n",
    "    threshold_90 = np.percentile(blue_conf.dropna(), 10)  # 10th percentile gives the lowest value for 90% of blue points above the threshold\n",
    "\n",
    "    # initialize variables for the best threshold and best percentages\n",
    "    best_threshold = threshold_90\n",
    "    best_blue_above = (blue_conf >= threshold_90).mean()  # percentage of blue points above the initial threshold\n",
    "    best_red_below = (red_conf < threshold_90).mean()  # percentage of red points below the initial threshold\n",
    "\n",
    "    # ensure at least 90% of blue points are above the initial threshold \n",
    "    if not np.isclose(best_blue_above, 0.9, atol=0.001) and best_blue_above < 0.9:\n",
    "        print(f\"Warning: Initial threshold_90 results in {best_blue_above * 100:.2f}% blue points above threshold for {keypoint_name}. Adjusting threshold.\")\n",
    "\n",
    "        # adjust threshold slightly upwards to ensure 90% of blue points are above it\n",
    "        threshold_90 = np.percentile(blue_conf.dropna(), 9.9)  # Adjust slightly upward to ensure 90% are above\n",
    "        best_threshold = threshold_90\n",
    "        best_blue_above = (blue_conf >= threshold_90).mean()  # Recalculate with adjusted threshold\n",
    "        best_red_below = (red_conf < threshold_90).mean()\n",
    "\n",
    "    # evaluate possible thresholds from 90th percentile down to the minimum blue confidence score\n",
    "    for threshold in np.linspace(threshold_90, blue_conf.min(), 100):\n",
    "        blue_above = (blue_conf >= threshold).mean()  # Percentage of blue points above the current threshold\n",
    "        \n",
    "        # calculate the percentage of red points below the current threshold\n",
    "        red_below = (red_conf < threshold).mean()  # Percentage of red points below the current threshold\n",
    "\n",
    "        # find the threshold that maximizes the red points below the threshold\n",
    "        if red_below > best_red_below:\n",
    "            best_threshold = threshold\n",
    "            best_red_below = red_below\n",
    "            best_blue_above = blue_above\n",
    "\n",
    "    # store the best threshold for the current keypoint\n",
    "    optimal_thresholds[keypoint_name] = best_threshold\n",
    "\n",
    "    # print the best threshold found for this keypoint\n",
    "    print(f\"Optimal threshold for {keypoint_name}: {best_threshold:.4f} | % of Blue Points Above: {best_blue_above * 100:.2f}% | % of Red Points Below: {best_red_below * 100:.2f}%\\n\")\n",
    "\n",
    "# Output the optimal thresholds for each keypoint\n",
    "print(\"\\nOptimal thresholds for all keypoints:\")\n",
    "for keypoint_name, threshold in optimal_thresholds.items():\n",
    "    print(f\"{keypoint_name}: {threshold:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot data of a single keypoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint_name = \"LHip\"\n",
    "\n",
    "# calculate normalized distance (distance / PDJ threshold)\n",
    "df_yolo[f'{keypoint_name}_normalized_distance'] = df_yolo[f'{keypoint_name}_distance'] / df_yolo['PDJ_thold']\n",
    "\n",
    "# create a mask for blue points\n",
    "blue_mask = (df_yolo[f'{keypoint_name}_detected'] == 1) | (df_yolo_inverse[f'{keypoint_name}_detected'] == 1)\n",
    "\n",
    "# separate data based on the mask\n",
    "blue_points = df_yolo[blue_mask]\n",
    "red_points = df_yolo[~blue_mask]\n",
    "\n",
    "print(f\"Minimum {keypoint_name} confidence score of points who failed PDJ threshold: {red_points.LHip_conf_p.min()}\")\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# plot detected points in blue\n",
    "plt.scatter(blue_points[f'{keypoint_name}_conf_p'], blue_points[f'{keypoint_name}_normalized_distance'], \n",
    "            color='blue', alpha=0.7, label='Within PDJ Threshold')\n",
    "# plot not detected points in red\n",
    "plt.scatter(red_points[f'{keypoint_name}_conf_p'], red_points[f'{keypoint_name}_normalized_distance'], \n",
    "            color='red', alpha=0.7, label='Outside PDJ Threshold')\n",
    "\n",
    "# add titles and legend\n",
    "plt.xlabel(f'{keypoint_name} Estimation Confidence Score')\n",
    "plt.ylabel('Normalized Distance from True Label')\n",
    "plt.title(f'Relationship Between YOLOv8 {keypoint_name} Estimation Confidence and Distance from Labelled Keypoint')\n",
    "plt.title(keypoint_name, fontsize=18)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot combined keypoint data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "keypoints = [\"RAnkle\", \"LAnkle\", \"RKnee\", \"LKnee\", \"RHip\", \"LHip\"]\n",
    "   \n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "for kp in keypoints:\n",
    "    # calculate normalized distance for each keypoint\n",
    "    df_yolo[f'{kp}_normalized_distance'] = df_yolo[f'{kp}_distance'] / df_yolo['PDJ_thold']\n",
    "    \n",
    "    # extract relevant columns and add to combined df\n",
    "    kp_df = pd.DataFrame({\n",
    "        'Confidence': df_yolo[f'{kp}_conf_p'],\n",
    "        'Normalized Distance': df_yolo[f'{kp}_normalized_distance'],\n",
    "        'Detected': (df_yolo[f'{kp}_detected'] == 1) | (df_yolo_inverse[f'{kp}_detected'] == 1)\n",
    "    })\n",
    "    \n",
    "    combined_df = pd.concat([combined_df, kp_df], ignore_index=True)\n",
    "\n",
    "# separate data based on detection status\n",
    "detected_points = combined_df[combined_df['Detected']]\n",
    "not_detected_points = combined_df[~combined_df['Detected']]\n",
    "\n",
    "# create scatter plot\n",
    "plt.figure()\n",
    "\n",
    "# plot detected points in blue\n",
    "plt.scatter(detected_points['Confidence'], detected_points['Normalized Distance'], \n",
    "            color='blue', alpha=0.7, label='Within PDJ Threshold')\n",
    "\n",
    "# plot not detected points in red\n",
    "plt.scatter(not_detected_points['Confidence'], not_detected_points['Normalized Distance'], \n",
    "            color='red', alpha=0.7, label='Outside PDJ Threshold')\n",
    "\n",
    "# add titles and legend\n",
    "plt.xlabel('Keypoint Estimation Confidence Score')\n",
    "plt.ylabel('Normalized Distance From True Label')\n",
    "plt.title('YOLOv8')\n",
    "plt.legend()\n",
    "plt.ylim(top=61)\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "print(\"Mean distance from true label: \" + str(not_detected_points['Normalized Distance'].mean()))\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
